Name: expert_replay_data_NO_NOISE/no_grasp/naive_only/CubeS/normal
Date: _02_24_21_1806
Saving Dir: expert_replay_data_NO_NOISE/no_grasp/naive_only/CubeS/normal

INPUT:
Policy dir: None
Expert Replay Buffer: None
Agent Replay Buffer: None

OUTPUT:
Policy: None
Agent Replay Buffer: expert_replay_data_NO_NOISE/no_grasp/naive_only/CubeS/normal/replay_buffer/
Output dir: expert_replay_data_NO_NOISE/no_grasp/naive_only/CubeS/normal/output
Output/ Tensorboard: None
Output/ Heatmap: expert_replay_data_NO_NOISE/no_grasp/naive_only/CubeS/normal/output/heatmap/expert
Output/ Results: None
---- SUCCESS INFO: ----
# Success: 12925
# Failures: 7075
# Total: 20000

PARAMS: 
Saving dir: Naive_Only_NO_Finger_NO_Grasp_Normal_20000_CubeS
Tensorboard index: Naive_Only_NO_Finger_NO_Grasp_Normal_20000_CubeS
Policy: DDPGfD
Requested_shapes: ['CubeS']
Requested Hand orientation: normal
Batch Size: 64
Expert Sampling Probability: 0.3
Number of Sampling Trajectories: 5
Grasp Reward: False
Save frequency: 1000
Policy update after: 100
Policy update frequency: 4
Policy update Amount: 100
PID MODE: naive_only, Num Grasp trials: 20000
Date: 02_25_21_0330

Final # of Successes: 12925
Final # of Failures: 7075
Shapes: ['CubeS']

Saved replay buffer to location: expert_replay_data_NO_NOISE/no_grasp/naive_only/CubeS/normal/replay_buffer/
replay_buffer.replay_ep_num (# episodes): 19999
replay_buffer.size (# trajectories): 423150
Output data saved at: expert_replay_data_NO_NOISE/no_grasp/naive_only/CubeS/normal